{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb6b71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import fitz \n",
    "from pydantic import BaseModel\n",
    "import os \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time \n",
    "from openai import OpenAI\n",
    "import json \n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, Distance, VectorParams\n",
    "import numpy as np \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c05b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "def pdf_to_text(pdf_path: str) -> str:\n",
    "    elements = partition_pdf(pdf_path, strategy=\"fast\")\n",
    "    return \"\\n\".join([el.text.strip() for el in elements if el.text.strip()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "308a8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining schema for input \n",
    "\n",
    "class ResumeInfo(BaseModel):\n",
    "    name: str\n",
    "    skills: list = []\n",
    "    education: list = []\n",
    "    work_experience: list = []\n",
    "    projects: list = []\n",
    "    filepath : str \n",
    "\n",
    "\n",
    "json_schema = ResumeInfo.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e17b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_call(prompt):\n",
    "    client = OpenAI(\n",
    "    base_url=\"http://172.16.2.214:8000/v1\", \n",
    "    api_key=\"-\" \n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-32B-Instruct-AWQ\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "   \n",
    "   extra_body={\"guided_json\": json_schema}\n",
    "    )\n",
    "\n",
    "    #print(response.choices[0].message.content)\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51d24c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the prompt as an input to the LLM \n",
    "def parsing_helper(markdown_text,filepath):\n",
    "  prompt = f\"\"\"\n",
    "  You are a precise and strict **Information Extraction Assistant**.\n",
    "\n",
    "  Your task is to extract structured data from **unstructured CV text**, strictly following the provided JSON schema.\n",
    "  add this filepath as well {filepath}\n",
    "\n",
    "  json schema as follow : \n",
    "        name: str\n",
    "        skills: list = []\n",
    "        education: list = []\n",
    "        work_experience: list = []\n",
    "        projects: list = []\n",
    "        filepath : str \n",
    "    \n",
    "\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Rules:\n",
    "  - Only extract information that is **explicitly stated** in the CV text.\n",
    "  - If a field is **missing**, use:'\n",
    "    - `null` for missing strings\n",
    "    - `[]` for missing lists\n",
    "  - Do **not** hallucinate, infer, summarize, or rewrite content.\n",
    "  - Preserve original text exactly as it appears.\n",
    "  - Return a **valid JSON object only** â€” no markdown, no extra explanation.\n",
    "  ### CV Text: \n",
    "\n",
    "  {markdown_text}\n",
    "\n",
    "  ### Output(matches the schema):\n",
    "\"\"\"\n",
    "  \n",
    "  return LLM_call(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2e06d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parser_pipeline(path):\n",
    "    candidates = []\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"{path} is not a valid directory!\")\n",
    "    print(\"Converting CV to text\")\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        ##Calling pdf_to_text and converting each into text and passing it to the llm \n",
    "\n",
    "        \n",
    "\n",
    "        text =  pdf_to_text(file_path)\n",
    "        \n",
    "        ## passing it to the LLM \n",
    "        structured_output = parsing_helper(text,file_path)\n",
    "\n",
    "        candidates.append(structured_output)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a342d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azeem\\AppData\\Local\\Temp\\ipykernel_13628\\3333303549.py:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  \n",
    "client.recreate_collection(\n",
    "collection_name=\"cv_data\",\n",
    "vectors_config={\n",
    "    \"skills\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"education\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"work_experience\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"projects\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38a0844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_fields = [\"skills\", \"education\", \"work_experience\", \"projects\"]\n",
    "\n",
    "###-------------------------------------------------------------------------\n",
    "def zero_vector(dim=384):\n",
    "    return [0.0] * dim\n",
    "###-------------------------------------------------------------------------\n",
    "def join_and_embed(field_list,embedding_model):\n",
    "    if not field_list:\n",
    "        return zero_vector()  \n",
    "    pieces = []\n",
    "    for item in field_list:\n",
    "        if isinstance(item, dict):\n",
    "         \n",
    "            pieces.append(\", \".join(f\"{k}: {v}\" for k, v in item.items()))\n",
    "        elif isinstance(item, str):\n",
    "            pieces.append(item)\n",
    "        else:\n",
    "       \n",
    "            pieces.append(str(item))\n",
    "    text = \" \".join(pieces)\n",
    "    return embedding_model.encode([text])[0].tolist()\n",
    "\n",
    "###-----------------------------------------------------------------------\n",
    "def insert_candidate(candidate, collection_name=\"cv_data\"):\n",
    "    vector_data = {\n",
    "        field: join_and_embed(candidate.get(field, []),embedding_model)\n",
    "        for field in required_fields\n",
    "    }\n",
    "    \n",
    "    payload = {}\n",
    "    if \"name\" in candidate:\n",
    "        payload[\"name\"] = candidate[\"name\"]\n",
    "    if \"filepath\" in candidate: \n",
    "        payload[\"filepath\"] = candidate[\"filepath\"]\n",
    "\n",
    "    # Point ID\n",
    "    point_id = candidate.get(\"id\", hash(candidate.get(\"name\", \"unknown\")) & 0xFFFFFFFFFFFFFFFF)\n",
    "\n",
    "    point = PointStruct(\n",
    "        id=point_id,\n",
    "        vector=vector_data,\n",
    "        payload=payload\n",
    "    )\n",
    "    \n",
    "    client.upsert(collection_name=collection_name, points=[point])\n",
    "    print(f\"Inserted: {payload.get('name', 'Unnamed')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a63b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating VEC DB \n",
    "def create_vec_db(candidates):\n",
    "    for i, candidate in enumerate(candidates): \n",
    "        print(\"Inserting candidate\")\n",
    "        insert_candidate(candidate)\n",
    "    scroll_result = client.scroll(\n",
    "    collection_name=\"cv_data\",\n",
    "    with_payload=True,\n",
    "    with_vectors=True,\n",
    "    limit=100\n",
    ")\n",
    "\n",
    "    # for point in scroll_result[0]:\n",
    "    #     print(f\"\\nCandidate ID: {point.id}\")\n",
    "    #     print(f\"Name: {point.payload.get('name', 'N/A')}\")\n",
    "    #     print(f\"Filepath: {point.payload.get('filepath', 'N/A')}\")  # âœ… This line shows the path\n",
    "    #     print(\"Vectors:\")\n",
    "    #     for vector_name, vector_values in point.vector.items():\n",
    "    #         print(f\" - {vector_name} ({len(vector_values)} dims)\")\n",
    "    #         print(f\"   {vector_values[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f15552db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_description_parser(job_description) : \n",
    "    \n",
    "    job_prompt = f\"\"\"\n",
    "    You are an **Information Extraction Assistant**.\n",
    "\n",
    "    Your task:\n",
    "    - Parse the provided **job description**.\n",
    "    - Extract **explicit information only** â€” ***do not infer, invent, or assume***.\n",
    "    - Output a **valid JSON object** that matches the schema shown below.\n",
    "\n",
    "    ### JSON schema:\n",
    "    {{\n",
    "    \"skills\": [ \"list of required skills as short strings\" ],\n",
    "    \"work_experience\": \"explicit description of required work experience, as a string\",\n",
    "    \"education\": \"explicit education or qualification requirements, as a string\",\n",
    "    \"projects\": [ \"list of explicitly mentioned types of projects or domains\" ]\n",
    "    }}\n",
    "\n",
    "    ### Rules:\n",
    "    - If a field is not present in the job description, use:\n",
    "    - an empty list `[]` for list fields,\n",
    "    - or `null` for string fields.\n",
    "    - Do **not** add any extra text outside the JSON.\n",
    "    - Do **not** add markdown or explanations.\n",
    "    - Preserve the original wording of the job description when filling fields.\n",
    "\n",
    "    ### Job Description:\n",
    "    {job_description}\n",
    "    ### Output(matches the schema):\n",
    " \"\"\"\n",
    "\n",
    "    return LLM_call(job_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f112c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Searching_Qdrant(parsed__job_description,top_k) : \n",
    "\n",
    "    job_vectors = {\n",
    "        field: join_and_embed(parsed__job_description.get(field, []), embedding_model)\n",
    "        for field in required_fields\n",
    "    }\n",
    "\n",
    "    fields = [\"skills\", \"education\", \"work_experience\", \"projects\"]\n",
    "    user_weights_raw = {}\n",
    "\n",
    "    print(\"Please enter weight for each field. Total should sum to 1 (e.g. 0.4, 0.2, etc.)\")\n",
    "\n",
    "    for field in fields:\n",
    "        while True:\n",
    "            try:\n",
    "                weight = float(input(f\"Enter weight for '{field}': \"))\n",
    "                if weight < 0:\n",
    "                    raise ValueError\n",
    "                user_weights_raw[field] = weight\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a non-negative number.\")\n",
    "\n",
    "    total_weight = sum(user_weights_raw.values())\n",
    "\n",
    "    if abs(total_weight - 1.0) > 1e-6:\n",
    "        print(f\"\\n Total weight entered is {total_weight:.3f}, normalizing to 1.\")\n",
    "        user_weights = {k: v / total_weight for k, v in user_weights_raw.items()}\n",
    "    else:\n",
    "        user_weights = user_weights_raw\n",
    "\n",
    "    print(\"\\n Normalized Weights:\")\n",
    "    for field, weight in user_weights.items():\n",
    "        print(f\"  {field}: {weight:.3f}\")\n",
    "\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for field in required_fields:\n",
    "        hits = client.search(\n",
    "            collection_name=\"cv_data\",\n",
    "            query_vector=(field, job_vectors[field]), \n",
    "            limit=top_k,\n",
    "            with_payload=True,\n",
    "            with_vectors=False  \n",
    "        )\n",
    "        results[field] = hits\n",
    "\n",
    "\n",
    "    score_board = defaultdict(float)\n",
    "\n",
    "    for field in results:\n",
    "        weight = user_weights.get(field, 0)\n",
    "        for hit in results[field]:\n",
    "            score_board[hit.id] += hit.score * weight\n",
    "    return score_board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f540344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def sorting_candidates(score_board,top_k): \n",
    "\n",
    "    ranked = sorted(score_board.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_candidates = []  \n",
    "    shown = 0\n",
    "\n",
    "    for candidate_id, total_score in ranked:\n",
    "        point = next(\n",
    "            (pt for pt in client.scroll(\n",
    "                collection_name=\"cv_data\",\n",
    "                with_payload=True,\n",
    "                with_vectors=False,\n",
    "                limit=100\n",
    "            )[0] if pt.id == candidate_id),\n",
    "            None\n",
    "        )\n",
    "        if point:\n",
    "            candidate_info = {\n",
    "                \"name\": point.payload.get(\"name\"),\n",
    "                \"filepath\": point.payload.get(\"filepath\"),\n",
    "                \"score\": round(total_score, 4),\n",
    "                \"id\": candidate_id\n",
    "            }\n",
    "            top_candidates.append(candidate_info)\n",
    "\n",
    "            # # Display\n",
    "            # print(f\"Name: {candidate_info['name']}\")\n",
    "            # print(f\"Filepath: {candidate_info['filepath']}\")\n",
    "            # print(f\"Score: {candidate_info['score']}\\n\")\n",
    "\n",
    "            shown += 1\n",
    "        if shown >= top_k:\n",
    "            break\n",
    "\n",
    "    return top_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60167294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(job_description,top_candidates,candidates,top_k):\n",
    "   prompt_3 = f\"\"\" You are an expert technical recruiter and AI career advisor. Use the information provided below to perform an in-depth candidate evaluation using semantic embeddings retrieved from a vector database (Qdrant).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§¾ Job Description\n",
    "\n",
    "{job_description}\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Top {top_k} Candidates from Vector Similarity Search : {top_candidates}\n",
    "\n",
    "These candidates were retrieved from the Qdrant vector database based on semantic similarity to the job description. Each candidate includes their resume filepath,a vector similarity score and id.\n",
    "---\n",
    "\n",
    "Here is all the candidates \n",
    "{candidates}\n",
    "\n",
    "### ðŸŽ¯ Task\n",
    "\n",
    "Analyze the candidates above with respect to the job description and perform the following:\n",
    "\n",
    "1. **Compare** each candidate's qualifications with the job description in terms of:\n",
    "   - Skills\n",
    "   - Work experience\n",
    "   - Relevant projects\n",
    "   - Educational background\n",
    "\n",
    "2. **Rank** the candidates from most to least suitable based on the job description and vector match scores.\n",
    "\n",
    "3. **Justify** your top 1â€“2 recommendations with detailed reasoning, focusing on fit for the role. Also the decision should not be eccentric to the match scores\n",
    "\n",
    "4. **Highlight Gaps**:\n",
    "   - Are there any key missing skills or misalignments?\n",
    "   - Are there strengths that go beyond the role?\n",
    "\n",
    "5. **Provide Insights**:\n",
    "   - Strengths and weaknesses of each candidate\n",
    "   - A comparison table showing each candidate's match to the job requirements\n",
    "   - Visual ideas: skill coverage bar chart or score comparison chart\n",
    "   - Suggest which candidate fits which kind of sub-role (e.g., research-focused, full-stack AI, deployment)\n",
    "\n",
    "6. Write in a **professional tone** suitable for HR and technical hiring managers.\n",
    "\n",
    "---\n",
    "\n",
    "Your goal is to aid the hiring manager in making a well-informed and confident decision based on both semantic similarity and practical job fit. Dont disclose any scores to the user in the output \n",
    "\n",
    " \"\"\"\n",
    "   \n",
    "   client = OpenAI(\n",
    "   base_url=\"http://172.16.2.214:8000/v1\", \n",
    "   api_key=\"-\" \n",
    "   )\n",
    "   response = client.chat.completions.create(\n",
    "   model=\"Qwen/Qwen2.5-32B-Instruct-AWQ\",\n",
    "   messages=[\n",
    "      {\"role\": \"user\", \"content\": prompt_3}\n",
    "      ],\n",
    "      )\n",
    "\n",
    "   print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb864ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "632f0aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### writing the main function for everything\n",
    "\n",
    "def main(): \n",
    "    \n",
    "    candidates = cv_parser_pipeline(\"Resumes\")\n",
    "\n",
    "    ## creating vec db \n",
    "    create_vec_db(candidates)\n",
    "\n",
    "    job_description = input(\"***Please Enter the Job Description***\")\n",
    "    parsed__job_description = job_description_parser(job_description)\n",
    "\n",
    "    top_k = int(input(\"Enter number of top candidates to display: \"))\n",
    "    score_board = Searching_Qdrant(parsed__job_description,top_k)\n",
    "\n",
    "    top_candidates = sorting_candidates(score_board,top_k)\n",
    "\n",
    "    return analysis(job_description,top_candidates,candidates,top_k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b4bdd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CV to text\n",
      "Inserting candidate\n",
      "Inserted: AHMAD RASHAD MOJEEB\n",
      "Inserting candidate\n",
      "Inserted: Muhammad Azeem Chaudhry\n",
      "Please enter weight for each field. Total should sum to 1 (e.g. 0.4, 0.2, etc.)\n",
      "\n",
      " Total weight entered is 2.000, normalizing to 1.\n",
      "\n",
      " Normalized Weights:\n",
      "  skills: 0.250\n",
      "  education: 0.250\n",
      "  work_experience: 0.250\n",
      "  projects: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azeem\\AppData\\Local\\Temp\\ipykernel_13628\\1888841853.py:40: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  hits = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Candidate Evaluation Report\n",
      "\n",
      "#### Overview\n",
      "This report evaluates two candidates against the job description for a Junior AI Engineer position. The evaluation covers skills, work experience, relevant projects, and educational background. Additionally, it provides insights into each candidate's strengths and weaknesses, highlighting gaps and areas where they exceed expectations.\n",
      "\n",
      "#### Candidate Comparison\n",
      "\n",
      "**1. Muhammad Azeem Chaudhry**\n",
      "- **Skills**: Extensive experience with Python, PyTorch, TensorFlow, and various machine learning libraries such as Scikit-Learn, Pandas, and NumPy. Strong foundation in NLP, deep learning frameworks, and model deployment using Docker and gRPC.\n",
      "- **Work Experience**: Multiple internships in AI/ML development, including roles at Atom Camp and E-strats. Experience with chatbot development, automated systems, and web application maintenance.\n",
      "- **Relevant Projects**: Developed AI-driven audio storytelling systems, traffic sign classifiers, and enhanced NLP models. Demonstrates hands-on experience with real-world applications.\n",
      "- **Educational Background**: Currently pursuing a Bachelor's degree in Artificial Intelligence from FAST, Islamabad, Pakistan. Coursework includes AI, NLP, and machine learning.\n",
      "\n",
      "**2. AHMAD RASHAD MOJEEB**\n",
      "- **Skills**: Proficient in multiple programming languages including Java, Python, C#, and C++. Familiar with frameworks like Spring Boot, .NET, React, and Git. Has experience with Docker and website deployment.\n",
      "- **Work Experience**: No professional work experience listed.\n",
      "- **Relevant Projects**: Engaged in diverse projects ranging from full-stack web applications to game development and operating system simulations. Showcases a broad range of technical skills but lacks specific AI/ML focus.\n",
      "- **Educational Background**: Currently pursuing a Bachelor's degree in Computer Science from FAST, Islamabad, Pakistan. Previous education includes A-levels and O-levels from Supernova School.\n",
      "\n",
      "#### Ranking\n",
      "\n",
      "Based on the evaluation criteria and considering the job description, here is the ranking of candidates:\n",
      "\n",
      "1. **Muhammad Azeem Chaudhry**\n",
      "2. **AHMAD RASHAD MOJEEB**\n",
      "\n",
      "#### Justification for Top Recommendations\n",
      "\n",
      "**Top Recommendation: Muhammad Azeem Chaudhry**\n",
      "- **Fit for the Role**: Muhammad Azeem Chaudhry has a strong alignment with the required skills for the Junior AI Engineer role. His extensive experience with Python, machine learning libraries, and deep learning frameworks directly matches the job requirements. His internships provide practical experience in developing and deploying AI solutions.\n",
      "- **Strengths**: He excels in NLP and has hands-on experience with various AI/ML projects. His involvement in internships also demonstrates his ability to work in a professional environment and collaborate with cross-functional teams.\n",
      "- **Gaps**: While he meets most of the job requirements, he may need additional exposure to some advanced AI/ML concepts and continuous learning to keep up with the latest advancements.\n",
      "\n",
      "**Second Recommendation: AHMAD RASHAD MOJEEB**\n",
      "- **Fit for the Role**: AHMAD RASHAD MOJEEB has a broad set of technical skills and a solid educational background. However, his lack of direct AI/ML experience and professional work history make him less aligned with the job description compared to Muhammad Azeem Chaudhry.\n",
      "- **Strengths**: His diverse project portfolio showcases strong problem-solving abilities and adaptability across different domains. His familiarity with Docker and web deployment is a plus.\n",
      "- **Gaps**: He needs more specific training and experience in AI/ML frameworks and tools to fully meet the job requirements.\n",
      "\n",
      "#### Highlighting Gaps and Strengths\n",
      "\n",
      "**Muhammad Azeem Chaudhry**\n",
      "- **Strengths**: Strong AI/ML background, practical experience, and hands-on projects.\n",
      "- **Gaps**: Limited exposure to advanced AI/ML concepts and continuous learning required.\n",
      "\n",
      "**AHMAD RASHAD MOJEEB**\n",
      "- **Strengths**: Broad technical skills, diverse project experience, and basic familiarity with AI/ML tools.\n",
      "- **Gaps**: Lack of direct AI/ML experience and professional work history.\n",
      "\n",
      "#### Insights and Comparison Table\n",
      "\n",
      "| Criteria              | Muhammad Azeem Chaudhry | AHMAD RASHAD MOJEEB |\n",
      "|-----------------------|-------------------------|----------------------|\n",
      "| Python Proficiency    | High                    | Moderate             |\n",
      "| ML Libraries          | High                    | Low                  |\n",
      "| Deep Learning         | High                    | Low                  |\n",
      "| NLP Experience        | High                    | Low                  |\n",
      "| Work Experience       | High                    | Low                  |\n",
      "| Project Relevance     | High                    | Moderate             |\n",
      "| Educational Background| High                    | High                 |\n",
      "\n",
      "#### Visual Ideas\n",
      "\n",
      "- **Skill Coverage Bar Chart**: Display the level of skill coverage for each candidate against the job requirements.\n",
      "- **Score Comparison Chart**: Show a visual comparison of how each candidate aligns with the job description.\n",
      "\n",
      "#### Sub-Role Fit\n",
      "\n",
      "- **Muhammad Azeem Chaudhry**: Fits well for a full-stack AI engineer role due to his broad experience and practical projects.\n",
      "- **AHMAD RASHAD MOJEEB**: Could be a good fit for a research-focused role with additional training in AI/ML.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Based on the evaluation, Muhammad Azeem Chaudhry is the strongest candidate for the Junior AI Engineer role due to his comprehensive skill set and practical experience. AHMAD RASHAD MOJEEB shows potential but would require additional training and experience in AI/ML to fully meet the job requirements.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9aea69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
