{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cb6b71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import fitz \n",
    "from pydantic import BaseModel\n",
    "import os \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time \n",
    "from openai import OpenAI\n",
    "import json \n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, Distance, VectorParams\n",
    "import numpy as np \n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8c05b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "def pdf_to_text(pdf_path: str) -> str:\n",
    "    elements = partition_pdf(pdf_path, strategy=\"fast\")\n",
    "    return \"\\n\".join([el.text.strip() for el in elements if el.text.strip()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "308a8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining schema for input \n",
    "\n",
    "class ResumeInfo(BaseModel):\n",
    "    name: str\n",
    "    skills: list = []\n",
    "    education: list = []\n",
    "    work_experience: list = []\n",
    "    projects: list = []\n",
    "    filepath : str \n",
    "\n",
    "\n",
    "json_schema = ResumeInfo.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b62de426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7df14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6e17b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_call(prompt):\n",
    "    client = OpenAI(\n",
    "    base_url=\"http://172.16.2.214:8000/v1\", \n",
    "    api_key=\"-\" \n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-32B-Instruct-AWQ\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "   \n",
    "   extra_body={\"guided_json\": json_schema}\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "51d24c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the prompt as an input to the LLM \n",
    "def parsing_helper(markdown_text,filepath):\n",
    "  prompt = f\"\"\"\n",
    "  You are a precise and strict **Information Extraction Assistant**.\n",
    "\n",
    "  Your task is to extract structured data from **unstructured CV text**, strictly following the provided JSON schema.\n",
    "  add this filepath as well {filepath}\n",
    "\n",
    "  json schema as follow : \n",
    "        name: str\n",
    "        skills: list = []\n",
    "        education: list = []\n",
    "        work_experience: list = []\n",
    "        projects: list = []\n",
    "        filepath : str \n",
    "    \n",
    "\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Rules:\n",
    "  - Only extract information that is **explicitly stated** in the CV text.\n",
    "  - If a field is **missing**, use:'\n",
    "    - `null` for missing strings\n",
    "    - `[]` for missing lists\n",
    "  - Do **not** hallucinate, infer, summarize, or rewrite content.\n",
    "  - Preserve original text exactly as it appears.\n",
    "  - Return a **valid JSON object only** — no markdown, no extra explanation.\n",
    "  ### CV Text: \n",
    "\n",
    "  {markdown_text}\n",
    "\n",
    "  ### Output(matches the schema):\n",
    "\"\"\"\n",
    "  \n",
    "  return LLM_call(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a2e06d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parser_pipeline(path):\n",
    "    candidates = []\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"{path} is not a valid directory!\")\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        ##Calling pdf_to_text and converting each into text and passing it to the llm \n",
    "\n",
    "        print(\"Converting CV to text\")\n",
    "\n",
    "        text =  pdf_to_text(file_path)\n",
    "        \n",
    "        ## passing it to the LLM \n",
    "        structured_output = parsing_helper(text,file_path)\n",
    "\n",
    "        candidates.append(structured_output)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "235ff422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CV to text\n",
      "{\n",
      "  \"name\": \"AHMAD RASHAD MOJEEB\",\n",
      "  \"skills\": [\n",
      "    \"Project Management: Hands-on experience with Jira for tracking tasks and managing sprints\",\n",
      "    \"Frameworks & Tools: Spring Boot, .NET, React, Git, MySQLL\",\n",
      "    \"Development Areas: Full-Stack Development, Game Development, and Operating Systems Simulation\",\n",
      "    \"Deployment: Docker (Containerisation), Website Deployment\",\n",
      "    \"Programming Languages: Java, Python, C#, SQL, Assembly, C++, C\"\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Computer Science\",\n",
      "      \"institution\": \"FAST | nuces\",\n",
      "      \"duration\": \"2022-2026\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Alevels\",\n",
      "      \"institution\": \"Supernova school\",\n",
      "      \"duration\": \"1Astar 2As\",\n",
      "      \"year\": \"2020-2022\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Olevels\",\n",
      "      \"institution\": \"Supernova school\",\n",
      "      \"duration\": \"6Astar 2As\",\n",
      "      \"year\": \"2018-2020\"\n",
      "    }\n",
      "  ],\n",
      "  \"work_experience\": [],\n",
      "  \"projects\": [\n",
      "    \"SportSync – Full-Stack Sports Event Management System (Spring Boot + React + API integration - worked as scrum master)\",\n",
      "    \"BookYourHall – Full-Stack Web Application (Spring Boot + React + mySQL)\",\n",
      "    \"ShopVerse – Online Marketplace Database System (C# .net + SQL)\",\n",
      "    \"TORCS Car Racing Simulation – Implemented using AI (Python, mlp-regressor)\",\n",
      "    \"Multi-Robot Path Planning in Dynamic Partially Observable Environments (Python)\",\n",
      "    \"Road Junction – Traffic Light Simulation (C++, implemented POSIX threads, thread synchronization and thread communication)\",\n",
      "    \"Pac-Man – Classic Arcade Game (Assembly Language)\",\n",
      "    \"Enchanted Labyrinth Explorer – Maze Navigation Game (C++, utilized AVL trees and path finding algorithms(Dijkstra) for maze navigation)\",\n",
      "    \"Dodge Em – Object-Oriented Game (C++, Focus on OOP principles eg encapsulation, abstraction, inheritance and polymorphism)\",\n",
      "    \"Chess Game (C++)\",\n",
      "    \"Tetris (C++)\"\n",
      "  ],\n",
      "  \"filepath\": \"Resumes\\\\Ahmad Rashad (7).pdf\"\n",
      "}\n",
      "Converting CV to text\n",
      "{\n",
      "  \"name\": \"Muhammad Azeem Chaudhry\",\n",
      "  \"skills\": [\n",
      "    \"Python: LLMs (Hugging Face Transformers, SpeechT5, RoBERTa), PyTorch, NLTK, Flask, Streamlit, gRPC, Pandas, NumPy, Matplotlib, OpenCV, Scikit-Learn, Jupyter, Librosa, PyAudio, SentencePiece, Torchaudio\",\n",
      "    \"Machine Learning: Logistic Regression, Decision Trees, Random Forest, Gradient Descent, Support Vector Machines (SVM), Artificial Neural Networks (ANN), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Batch Normalization, Dropout, K-Means Clustering, K-Nearest Neighbors (KNN), PCA, Activation Functions, Backpropagation\",\n",
      "    \"NLP: Tokenisation, Text Preprocessing, Sentiment Analysis, Transformer Architectures, Attention Mechanisms, Sequence-to-Sequence Models, SpeechT5, RoBERTa, Cross-Task Attention, Word Embeddings (Word2Vec), Intent & Slot Modeling\",\n",
      "    \"Deployment and Tools: Docker, gRPC, Postman, Streamlit, Git, Linux CLI, SPARQL, Jupyter, Colab, Kaggle\",\n",
      "    \"Database Management: SQL, JSON, REST APIs\",\n",
      "    \"C/C++: Object-Oriented Programming, Data Structures, File I/O, STL, Multithreading\",\n",
      "    \"Java Script (Basic)\",\n",
      "    \"Soft Skills: Problem Solving and Analytical Thinking, Communication and Collaboration, Time Management and Multitasking, Adaptability in Fast-Paced Environments, Initiative and Self-Learning, Technical Documentation and Reporting\"\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Bachelor's\",\n",
      "      \"institution\": \"FAST, BS Artificial Intelligence\",\n",
      "      \"years\": \"2022 – 2026\",\n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"main_courses\": [\n",
      "        \"Artificial Neural Networks\",\n",
      "        \"Database Systems\",\n",
      "        \"Parallel and Distributed Computing\",\n",
      "        \"Natural Language Processing\",\n",
      "        \"Digital Image Processing\",\n",
      "        \"Artificial Intelligence\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"position\": \"AI/ML Developer Intern\",\n",
      "      \"company\": \"Atom Camp\",\n",
      "      \"duration\": \"08/2024 – 01/2025\",\n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"description\": \"Contributed to the design and deployment of AI solutions, including LLM-based chatbots and learning management tools. Focused on enhancing user interactions, improving model responses, and supporting system scalability through Python, Transformers, and RESTful APIs.\"\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Al intern\",\n",
      "      \"company\": \"Atom Camp\",\n",
      "      \"duration\": \"07/2024 – 08/2024\",\n",
      "     \n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"description\": \"Collaborated with a team to develop a chatbot for Atomcamp's website using Google API and open-source LLMs, enhancing user interaction and support. Contributed to the development of an automated attendance system, streamlining daily attendance data into a consolidated record.\"\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Software Developer Intern\",\n",
      "      \"company\": \"E-strats\",\n",
      "      \"duration\": \"06/2021 – 07/2021\",\n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"description\": \"Developed and maintained web applications using .NET and C#. Worked on user interfaces with HTML and CSS. Participated in code reviews to ensure code quality and adherence to standards.\"\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Text2Story\",\n",
      "      \"description\": \"Developed an AI-driven audio storytelling system that converts written narratives into expressive audio using SpeechT5 with contextual prosody, leveraging Librosa, Torchaudio, and Parler TTS for tone modulation and voice synthesis. Integrated data preprocessing and model orchestration with PyTorch and Transformers.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Traffic Sign Classification\",\n",
      "      \"description\": \"Designed a rule-based image classifier using NumPy and traditional computer vision techniques to detect traffic signs based on color, shape, and geometric features, emphasizing computational efficiency over deep learning approaches.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"CTRA-N Based NLP Enhancements\",\n",
      "      \"description\": \"Reproduced and enhanced the CTRAN model by replacing BERT with RoBERTa and integrating cross-task attention mechanisms, resulting in improved performance on standard NLU benchmarks for intent classification and slot filling.\"\n",
      "    }\n",
      "  ],\n",
      "  \"filepath\": \"Resumes\\\\Muhammad Azeem Chaudhry's Resume.pdf\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "candidates = cv_parser_pipeline(\"Resumes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1d682cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'AHMAD RASHAD MOJEEB',\n",
       "  'skills': ['Project Management: Hands-on experience with Jira for tracking tasks and managing sprints',\n",
       "   'Frameworks & Tools: Spring Boot, .NET, React, Git, MySQLL',\n",
       "   'Development Areas: Full-Stack Development, Game Development, and Operating Systems Simulation',\n",
       "   'Deployment: Docker (Containerisation), Website Deployment',\n",
       "   'Programming Languages: Java, Python, C#, SQL, Assembly, C++, C'],\n",
       "  'education': [{'degree': 'Bachelor of Computer Science',\n",
       "    'institution': 'FAST | nuces',\n",
       "    'duration': '2022-2026'},\n",
       "   {'degree': 'Alevels',\n",
       "    'institution': 'Supernova school',\n",
       "    'duration': '1Astar 2As',\n",
       "    'year': '2020-2022'},\n",
       "   {'degree': 'Olevels',\n",
       "    'institution': 'Supernova school',\n",
       "    'duration': '6Astar 2As',\n",
       "    'year': '2018-2020'}],\n",
       "  'work_experience': [],\n",
       "  'projects': ['SportSync – Full-Stack Sports Event Management System (Spring Boot + React + API integration - worked as scrum master)',\n",
       "   'BookYourHall – Full-Stack Web Application (Spring Boot + React + mySQL)',\n",
       "   'ShopVerse – Online Marketplace Database System (C# .net + SQL)',\n",
       "   'TORCS Car Racing Simulation – Implemented using AI (Python, mlp-regressor)',\n",
       "   'Multi-Robot Path Planning in Dynamic Partially Observable Environments (Python)',\n",
       "   'Road Junction – Traffic Light Simulation (C++, implemented POSIX threads, thread synchronization and thread communication)',\n",
       "   'Pac-Man – Classic Arcade Game (Assembly Language)',\n",
       "   'Enchanted Labyrinth Explorer – Maze Navigation Game (C++, utilized AVL trees and path finding algorithms(Dijkstra) for maze navigation)',\n",
       "   'Dodge Em – Object-Oriented Game (C++, Focus on OOP principles eg encapsulation, abstraction, inheritance and polymorphism)',\n",
       "   'Chess Game (C++)',\n",
       "   'Tetris (C++)'],\n",
       "  'filepath': 'Resumes\\\\Ahmad Rashad (7).pdf'},\n",
       " {'name': 'Muhammad Azeem Chaudhry',\n",
       "  'skills': ['Python: LLMs (Hugging Face Transformers, SpeechT5, RoBERTa), PyTorch, NLTK, Flask, Streamlit, gRPC, Pandas, NumPy, Matplotlib, OpenCV, Scikit-Learn, Jupyter, Librosa, PyAudio, SentencePiece, Torchaudio',\n",
       "   'Machine Learning: Logistic Regression, Decision Trees, Random Forest, Gradient Descent, Support Vector Machines (SVM), Artificial Neural Networks (ANN), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Batch Normalization, Dropout, K-Means Clustering, K-Nearest Neighbors (KNN), PCA, Activation Functions, Backpropagation',\n",
       "   'NLP: Tokenisation, Text Preprocessing, Sentiment Analysis, Transformer Architectures, Attention Mechanisms, Sequence-to-Sequence Models, SpeechT5, RoBERTa, Cross-Task Attention, Word Embeddings (Word2Vec), Intent & Slot Modeling',\n",
       "   'Deployment and Tools: Docker, gRPC, Postman, Streamlit, Git, Linux CLI, SPARQL, Jupyter, Colab, Kaggle',\n",
       "   'Database Management: SQL, JSON, REST APIs',\n",
       "   'C/C++: Object-Oriented Programming, Data Structures, File I/O, STL, Multithreading',\n",
       "   'Java Script (Basic)',\n",
       "   'Soft Skills: Problem Solving and Analytical Thinking, Communication and Collaboration, Time Management and Multitasking, Adaptability in Fast-Paced Environments, Initiative and Self-Learning, Technical Documentation and Reporting'],\n",
       "  'education': [{'degree': \"Bachelor's\",\n",
       "    'institution': 'FAST, BS Artificial Intelligence',\n",
       "    'years': '2022 – 2026',\n",
       "    'location': 'Islamabad, Pakistan',\n",
       "    'main_courses': ['Artificial Neural Networks',\n",
       "     'Database Systems',\n",
       "     'Parallel and Distributed Computing',\n",
       "     'Natural Language Processing',\n",
       "     'Digital Image Processing',\n",
       "     'Artificial Intelligence']}],\n",
       "  'work_experience': [{'position': 'AI/ML Developer Intern',\n",
       "    'company': 'Atom Camp',\n",
       "    'duration': '08/2024 – 01/2025',\n",
       "    'location': 'Islamabad, Pakistan',\n",
       "    'description': 'Contributed to the design and deployment of AI solutions, including LLM-based chatbots and learning management tools. Focused on enhancing user interactions, improving model responses, and supporting system scalability through Python, Transformers, and RESTful APIs.'},\n",
       "   {'position': 'Al intern',\n",
       "    'company': 'Atom Camp',\n",
       "    'duration': '07/2024 – 08/2024',\n",
       "    'location': 'Islamabad, Pakistan',\n",
       "    'description': \"Collaborated with a team to develop a chatbot for Atomcamp's website using Google API and open-source LLMs, enhancing user interaction and support. Contributed to the development of an automated attendance system, streamlining daily attendance data into a consolidated record.\"},\n",
       "   {'position': 'Software Developer Intern',\n",
       "    'company': 'E-strats',\n",
       "    'duration': '06/2021 – 07/2021',\n",
       "    'location': 'Islamabad, Pakistan',\n",
       "    'description': 'Developed and maintained web applications using .NET and C#. Worked on user interfaces with HTML and CSS. Participated in code reviews to ensure code quality and adherence to standards.'}],\n",
       "  'projects': [{'name': 'Text2Story',\n",
       "    'description': 'Developed an AI-driven audio storytelling system that converts written narratives into expressive audio using SpeechT5 with contextual prosody, leveraging Librosa, Torchaudio, and Parler TTS for tone modulation and voice synthesis. Integrated data preprocessing and model orchestration with PyTorch and Transformers.'},\n",
       "   {'name': 'Traffic Sign Classification',\n",
       "    'description': 'Designed a rule-based image classifier using NumPy and traditional computer vision techniques to detect traffic signs based on color, shape, and geometric features, emphasizing computational efficiency over deep learning approaches.'},\n",
       "   {'name': 'CTRA-N Based NLP Enhancements',\n",
       "    'description': 'Reproduced and enhanced the CTRAN model by replacing BERT with RoBERTa and integrating cross-task attention mechanisms, resulting in improved performance on standard NLU benchmarks for intent classification and slot filling.'}],\n",
       "  'filepath': \"Resumes\\\\Muhammad Azeem Chaudhry's Resume.pdf\"}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2a342d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azeem\\AppData\\Local\\Temp\\ipykernel_16540\\3333303549.py:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  \n",
    "client.recreate_collection(\n",
    "collection_name=\"cv_data\",\n",
    "vectors_config={\n",
    "    \"skills\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"education\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"work_experience\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"projects\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "38a0844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_fields = [\"skills\", \"education\", \"work_experience\", \"projects\"]\n",
    "\n",
    "###-------------------------------------------------------------------------\n",
    "def zero_vector(dim=384):\n",
    "    return [0.0] * dim\n",
    "###-------------------------------------------------------------------------\n",
    "def join_and_embed(field_list,embedding_model):\n",
    "    if not field_list:\n",
    "        return zero_vector()  \n",
    "    pieces = []\n",
    "    for item in field_list:\n",
    "        if isinstance(item, dict):\n",
    "         \n",
    "            pieces.append(\", \".join(f\"{k}: {v}\" for k, v in item.items()))\n",
    "        elif isinstance(item, str):\n",
    "            pieces.append(item)\n",
    "        else:\n",
    "       \n",
    "            pieces.append(str(item))\n",
    "    text = \" \".join(pieces)\n",
    "    return embedding_model.encode([text])[0].tolist()\n",
    "\n",
    "###-----------------------------------------------------------------------\n",
    "def insert_candidate(candidate, collection_name=\"cv_data\"):\n",
    "    vector_data = {\n",
    "        field: join_and_embed(candidate.get(field, []),embedding_model)\n",
    "        for field in required_fields\n",
    "    }\n",
    "    \n",
    "    payload = {}\n",
    "    if \"name\" in candidate:\n",
    "        payload[\"name\"] = candidate[\"name\"]\n",
    "\n",
    "    # Point ID\n",
    "    point_id = candidate.get(\"id\", hash(candidate.get(\"name\", \"unknown\")) & 0xFFFFFFFFFFFFFFFF)\n",
    "\n",
    "    point = PointStruct(\n",
    "        id=point_id,\n",
    "        vector=vector_data,\n",
    "        payload=payload\n",
    "    )\n",
    "    client.upsert(collection_name=collection_name, points=[point])\n",
    "    print(f\"Inserted: {payload.get('name', 'Unnamed')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6a63b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating VEC DB \n",
    "def create_vec_db(candidates):\n",
    "    for i, candidate in enumerate(candidates): \n",
    "        print(\"Inserting candidate\")\n",
    "        insert_candidate(candidate)\n",
    "    scroll_result = client.scroll(\n",
    "    collection_name=\"cv_data\",\n",
    "    with_payload=True,\n",
    "    with_vectors=True,\n",
    "    limit=100\n",
    ")\n",
    "\n",
    "    for point in scroll_result[0]:\n",
    "        print(f\"\\nCandidate ID: {point.id}\")\n",
    "        print(f\"Name: {point.payload.get('name', 'N/A')}\")\n",
    "        print(\"Vectors:\")\n",
    "        for vector_name, vector_values in point.vector.items():\n",
    "            print(f\" - {vector_name} ({len(vector_values)} dims)\")\n",
    "            print(f\"   {vector_values[:10]}...\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8f96d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting candidate\n",
      "Inserted: AHMAD RASHAD MOJEEB\n",
      "Inserting candidate\n",
      "Inserted: Muhammad Azeem Chaudhry\n",
      "\n",
      "Candidate ID: 3803328281084053030\n",
      "Name: AHMAD RASHAD MOJEEB\n",
      "Vectors:\n",
      " - work_experience (384 dims)\n",
      "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...\n",
      " - education (384 dims)\n",
      "   [-0.051823772, -0.03190962, -0.014669334, 0.0022549776, -0.052440222, -0.06750166, -0.13645282, -0.00560706, -0.05132441, -0.01696106]...\n",
      " - skills (384 dims)\n",
      "   [-0.05399983, -0.024360845, -0.009617732, 0.009675335, 0.0064823, -0.068843395, 0.028106099, -0.0030010412, -0.06823482, 0.069343664]...\n",
      " - projects (384 dims)\n",
      "   [-0.009110181, -0.020662395, -0.028295567, -0.055782888, -0.030762274, -0.015234647, -0.06913017, 0.03892276, -0.08747218, 0.06663907]...\n",
      "\n",
      "Candidate ID: 5292380097305211120\n",
      "Name: Muhammad Azeem Chaudhry\n",
      "Vectors:\n",
      " - work_experience (384 dims)\n",
      "   [-0.057737976, -0.024317201, 0.010416603, 0.019773517, 0.01422782, -0.044006996, 0.002627371, -0.0036363723, -0.036899183, -0.03198545]...\n",
      " - projects (384 dims)\n",
      "   [-0.03959531, -0.09473572, 0.025652448, -0.054258443, 0.0010956578, 0.029833755, -0.0011511324, -0.051974535, -0.0009792366, -0.08130918]...\n",
      " - skills (384 dims)\n",
      "   [-0.08107303, -0.18257825, -0.008319617, -0.0040023117, 0.06360502, -0.0043624775, -0.048732035, 0.030923348, -0.017590592, -0.009718532]...\n",
      " - education (384 dims)\n",
      "   [-0.021256179, -0.085238256, 0.02810062, 0.023358196, -0.05861551, -0.058037534, -0.08238744, -0.017035617, -0.083069034, 0.00675746]...\n"
     ]
    }
   ],
   "source": [
    "create_vec_db(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f15552db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_description_parser(job_description) : \n",
    "    \n",
    "    job_prompt = f\"\"\"\n",
    "    You are an **Information Extraction Assistant**.\n",
    "\n",
    "    Your task:\n",
    "    - Parse the provided **job description**.\n",
    "    - Extract **explicit information only** — ***do not infer, invent, or assume***.\n",
    "    - Output a **valid JSON object** that matches the schema shown below.\n",
    "\n",
    "    ### JSON schema:\n",
    "    {{\n",
    "    \"skills\": [ \"list of required skills as short strings\" ],\n",
    "    \"work_experience\": \"explicit description of required work experience, as a string\",\n",
    "    \"education\": \"explicit education or qualification requirements, as a string\",\n",
    "    \"projects\": [ \"list of explicitly mentioned types of projects or domains\" ]\n",
    "    }}\n",
    "\n",
    "    ### Rules:\n",
    "    - If a field is not present in the job description, use:\n",
    "    - an empty list `[]` for list fields,\n",
    "    - or `null` for string fields.\n",
    "    - Do **not** add any extra text outside the JSON.\n",
    "    - Do **not** add markdown or explanations.\n",
    "    - Preserve the original wording of the job description when filling fields.\n",
    "\n",
    "    ### Job Description:\n",
    "    {job_description}\n",
    "    ### Output(matches the schema):\n",
    " \"\"\"\n",
    "\n",
    "    return LLM_call(job_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "84a96be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Junior AI Engineer\",\n",
      "    \"skills\": [\"Python\", \"NumPy\", \"Pandas\", \"TensorFlow\", \"PyTorch\", \"Git\", \"data structures\", \"algorithms\"],\n",
      "    \"work_experience\": [\"Prior experience with Git and version control.\", \"Previous internship or project experience in machine learning.\"],\n",
      "    \"projects\": [\"Please share links to GitHub, Kaggle, or any relevant work that showcases your ML projects.\"],\n",
      "    \"filepath\": \"job_description.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_description = input(\"***Please Enter the Job Description***\")\n",
    "parsed__job_description = job_description_parser(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9f112c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generating embeddings of the query input \n",
    "# embedding_vectors = {}\n",
    "# for field in weights:\n",
    "#     vec = embedding_model.encode([query_texts[field]])[0]\n",
    "#     embedding_vectors[field] = vec * weights[field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e799aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_named_vectors = {\n",
    "#     \"skills\": embedding_vectors[\"skills\"],\n",
    "#     \"education\": embedding_vectors[\"education\"],\n",
    "#     \"work_experience\": embedding_vectors[\"work_experience\"],\n",
    "#     \"projects\": embedding_vectors[\"projects\"],\n",
    "# }\n",
    "\n",
    "# query_named_vectors = {\n",
    "#     k: v.tolist() if hasattr(v, \"tolist\") else list(v)\n",
    "#     for k, v in query_named_vectors.items()\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7066d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, vec in query_named_vectors.items():\n",
    "#     print(f\"{name}: {len(vec)} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1f4dfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search_skills = client.query_points(\n",
    "#     collection_name=\"cv_data\",\n",
    "#     query=query_named_vectors['skills'],\n",
    "#     using=\"skills\",\n",
    "#     limit=100,\n",
    "#     with_payload=True\n",
    "# )\n",
    "\n",
    "# search_work = client.query_points(\n",
    "#     collection_name=\"cv_data\",\n",
    "#     query=query_named_vectors['work_experience'],\n",
    "#     using=\"work_experience\",\n",
    "#     limit=100,\n",
    "#     with_payload=True\n",
    "# )\n",
    "\n",
    "# search_edu = client.query_points(\n",
    "#     collection_name=\"cv_data\",\n",
    "#     query=query_named_vectors['education'],\n",
    "#     using=\"education\",\n",
    "#     limit=100,\n",
    "#     with_payload=True\n",
    "# )\n",
    "\n",
    "# search_projects = client.query_points(\n",
    "#     collection_name=\"cv_data\",\n",
    "#     query=query_named_vectors['projects'],\n",
    "#     using=\"projects\",\n",
    "#     limit=100,\n",
    "#     with_payload=True\n",
    "# )\n",
    "\n",
    "\n",
    "# combined_scores = {}\n",
    "\n",
    "# def accumulate_scores(results):\n",
    "#     for point in results.points:\n",
    "#         cid = point.id\n",
    "#         combined_scores.setdefault(\n",
    "#             cid,\n",
    "#             {\"name\": point.payload.get('name', 'N/A'), \"score\": 0.0}\n",
    "#         )\n",
    "#         combined_scores[cid][\"score\"] += point.score\n",
    "\n",
    "# accumulate_scores(search_skills)\n",
    "# accumulate_scores(search_work)\n",
    "# accumulate_scores(search_edu)\n",
    "# accumulate_scores(search_projects)\n",
    "\n",
    "\n",
    "# sorted_candidates = sorted(\n",
    "#     combined_scores.values(),\n",
    "#     key=lambda x: x['score'],\n",
    "#     reverse=True\n",
    "# )\n",
    "\n",
    "# # Print top-K\n",
    "# top_k = 5\n",
    "# print(f\"\\nTop {top_k} Candidates:\\n\")\n",
    "# for cand in sorted_candidates[:top_k]:\n",
    "#     print(f\"{cand['name']} | Score: {cand['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21306fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
