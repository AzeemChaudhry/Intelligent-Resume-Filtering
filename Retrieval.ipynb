{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d4ae0e",
   "metadata": {},
   "source": [
    "#### installing the necessary libraries needed to make the schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb6b71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import fitz # pymupdf (fitz is a module inside pymupdf that we are using)\n",
    "from pydantic import BaseModel\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c05b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating a function for parsing pdfs (resumes)\n",
    "def pdf_to_markdown(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        text = page.get_text()\n",
    "        # Remove characters that can't be encoded in UTF-8\n",
    "        cleaned_text = text.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")\n",
    "        full_text += cleaned_text\n",
    "\n",
    "    return full_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d5cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = pdf_to_markdown(r\"C:\\Users\\Azeem\\Documents\\CARE\\Intelligent-Resume-Filtering\\Resumes\\Ahmad Rashad (7).pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f982aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOBBIES\n",
      "CONTACT\n",
      "SKILLS\n",
      "+92-348-5416025\n",
      "ahmadrashadmojeeb@gmail\n",
      ".com\n",
      "NV-16, Isra Residence,\n",
      "Sector H-12, NUST,\n",
      "Islamabad\n",
      "Project Management: Hands-\n",
      "on experience with Jira for\n",
      "tracking tasks and managing\n",
      "sprints\n",
      "Frameworks & Tools: Spring\n",
      "Boot, .NET, React, Git,\n",
      "MySQLL\n",
      "Development Areas: Full-\n",
      "Stack Development, Game\n",
      "Development, and Operating\n",
      "Systems Simulation\n",
      "Deployment: Docker\n",
      "(Containerisation), Website\n",
      "Deployment\n",
      "Programming Languages:\n",
      "Java, Python, C#, SQL,\n",
      "Assembly, C++, C\n",
      "Firebase, mongoDB\n",
      "AHMAD RASHAD MOJEEB\n",
      "PROJECTS\n",
      "EDUCATION\n",
      "SUMMARY\n",
      "A Computer Science student at FAST with hands-on experience in full-\n",
      "stack development, DevOps, and Agile methodologies through academic\n",
      "projects and teamwork.\n",
      "Proficient in Java, C++, React, Spring Boot, SQL, and Docker, with a strong\n",
      "foundation in data structures, algorithms, and operating systems.\n",
      "2022-2026\n",
      "Bachelor of Computer Science\n",
      "FAST | nuces\n",
      "2020-2022\n",
      "Alevels  -  1Astar 2As\n",
      "Supernova school\n",
      "i221175@nu.edu.pk\n",
      "SportSync â€“ Full-Stack Sports Event Management System\n",
      "(Spring Boot + React + api integration - worked as scrum master)\n",
      "BookYourHall â€“ Full-Stack Web Application\n",
      "(Spring Boot + React + mySQL)\n",
      "ShopVerse â€“ Online Marketplace Database System\n",
      "(C# .net + SQL)\n",
      "TORCS Car Racing Simulation â€“ Implemented using AI\n",
      "(Python, mlp-regressor)\n",
      "Multi-Robot Path Planning in Dynamic Partially Observable Environments\n",
      "(Pyhton)\n",
      "Road Junction â€“ Traffic Light Simulation\n",
      "(C++, implemented POSIX threads, thread synchronization and thread\n",
      "communication)\n",
      "Pac-Man â€“ Classic Arcade Game\n",
      "(Assembly Language)\n",
      "Enchanted Labyrinth Explorer â€“ Maze Navigation Game\n",
      "(C++, utilized AVL trees and path finding algorithms(dijkstra) for maze\n",
      "navigation)\n",
      "Dodge Em â€“ Object-Oriented Game\n",
      "(C++, Focus on OOP principles eg encapsulation, abstraction, inheritance\n",
      "and polymorphism )\n",
      "Chess Game (C++)\n",
      "Tetris (C++)\n",
      "LINKS\n",
      "https://github.com/ahmadra\n",
      "shad\n",
      "https://www.linkedin.com/i\n",
      "n/ahmad-rashad-mojeeb-\n",
      "78ab25250/?\n",
      "trk=opento_sprofile_topcard\n",
      "Play football at university\n",
      "level, swim competitively\n",
      "with hopes to win at HEC,\n",
      "ride horses, and\n",
      "occasionally hit the gym.\n",
      "Olevels - 6Astar 2As\n",
      "2018-2020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308a8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining schema for input \n",
    "\n",
    "class ResumeInfo(BaseModel):\n",
    "    name: str\n",
    "    skills: list = []\n",
    "    education: list = []\n",
    "    work_experience: list = []\n",
    "    projects: list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda63c9",
   "metadata": {},
   "source": [
    "### Loading LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62de426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Azeem\\Documents\\CARE\\Intelligent-Resume-Filtering\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea0fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloading the model locally \n",
    "\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "save_path = \"./models/TinyLlama-1.1B-Chat\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if os.path.exists(save_path) and os.path.isdir(save_path):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(save_path)\n",
    "\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    model.save_pretrained(save_path)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2507d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the prompt as an input to the LLM \n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a precise and strict **Information Extraction Assistant**.\n",
    "\n",
    "Your task is to extract structured data from **unstructured CV text**, strictly following the provided JSON schema.\n",
    "\n",
    "---\n",
    "\n",
    "### Rules:\n",
    "- Only extract information that is **explicitly stated** in the CV text.\n",
    "- If a field is **missing**, use:\n",
    "  - `null` for missing strings\n",
    "  - `[]` for missing lists\n",
    "- Do **not** hallucinate, infer, summarize, or rewrite content.\n",
    "- Preserve original text exactly as it appears.\n",
    "- Return a **valid JSON object only** â€” no markdown, no extra explanation.\n",
    "\n",
    "---\n",
    "\n",
    "### JSON Schema (strict):\n",
    "```json\n",
    "{{\n",
    "  \"name\": string,\n",
    "  \"skills\": list of strings,\n",
    "  \"education\": list of strings,\n",
    "  \"work_experience\": list of strings,\n",
    "  \"projects\": list of strings\n",
    "}}\n",
    "\n",
    "### CV Text: \n",
    "\n",
    "{markdown_text}\n",
    "\n",
    "### Output(matches the schema):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ebfff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed, time taken 0.129241943359375\n",
      "Generation completed, Time taken : 317.1555962562561\n"
     ]
    }
   ],
   "source": [
    "## tokenizing the input prompt \n",
    "\n",
    "start_tokenize = time.time()\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "end_tokenize = time.time()\n",
    "\n",
    "print(f\"Tokenization completed, time taken {end_tokenize - start_tokenize}\")\n",
    "\n",
    "start_generate = time.time()\n",
    "## passing the tokenized input into the model \n",
    "with torch.no_grad():  \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=400,       \n",
    "        do_sample=False,          \n",
    "        temperature=0.01,          \n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "\n",
    "end_generate = time.time()\n",
    "\n",
    "print(f\"Generation completed, Time taken : {end_generate - start_generate}\")\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fb147f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Ahmad Rashad Mojeeb\",\n",
      "  \"skills\": [\"Java\", \"C++\", \"React\", \"Spring Boot\", \"SQL\", \"Docker\", \"Firebase\", \"MongoDB\", \"AHMAD RASHAD MOJEEB\"],\n",
      "  \"education\": [\"Bachelor of Computer Science\", \"Alevels 1Astar 2As\", \"Supernova school\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\", \"i221175@nu.edu.pk\", \"SportSync\",\n"
     ]
    }
   ],
   "source": [
    "print(response.replace(prompt, \"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "612987ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data = response.replace(prompt,\"\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0857be",
   "metadata": {},
   "source": [
    "### Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5662a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, Distance, VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a342d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting locally \n",
    "client = QdrantClient(\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6609a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e47792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 384\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Sample text for embedding\"\n",
    "embedding = embedding_model.encode(sample_text)\n",
    "embedding_size = len(embedding)\n",
    "print(f\"Embedding size: {embedding_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a0844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azeem\\AppData\\Local\\Temp\\ipykernel_18712\\424799661.py:1: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    }
   ],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"cv_data\",\n",
    "    vectors_config={\n",
    "        \"skills\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "        \"education\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "        \"work_experience\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "        \"projects\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    }\n",
    ")\n",
    "\n",
    "def zero_vector(dim=384):\n",
    "    return [0.0] * dim\n",
    "\n",
    "def join_and_embed(field_list):\n",
    "    if not field_list:\n",
    "        return zero_vector()  # Field exists but empty\n",
    "    text = \" \".join(field_list)\n",
    "    return embedding_model.encode([text])[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2908cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_fields = [\"skills\", \"education\", \"work_experience\", \"projects\"]\n",
    "def insert_candidate(candidate: dict,collection_name = \"cv_data\"):\n",
    "   \n",
    "    vector_data = {\n",
    "        field: join_and_embed(candidate.get(field, []))\n",
    "        for field in required_fields\n",
    "    }\n",
    "\n",
    "    payload = {}\n",
    "    if \"name\" in candidate:\n",
    "        payload[\"name\"] = candidate[\"name\"]\n",
    "\n",
    "    # Point ID: fallback if missing\n",
    "    point_id = candidate.get(\"id\", hash(candidate.get(\"name\", \"unknown\")))\n",
    "\n",
    "    point = PointStruct(\n",
    "        id=point_id,\n",
    "        vector=vector_data,\n",
    "        payload=payload\n",
    "    )\n",
    "    client.upsert(collection_name=collection_name, points=[point])\n",
    "    print(f\"Inserted: {payload.get('name', 'Unnamed')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9e878a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted: Sara Qureshi\n",
      "Inserted: Ali Raza\n",
      "Inserted: Hira Khalid\n",
      "Inserted: Muhammad Azeem\n"
     ]
    }
   ],
   "source": [
    "candidates = [\n",
    "    {\n",
    "        \"name\": \"Sara Qureshi\",\n",
    "        \"skills\": [\"Python\", \"TensorFlow\", \"Pandas\", \"Scikit-learn\", \"SQL\", \"Docker\"],\n",
    "        \"education\": [\n",
    "            \"BS in Artificial Intelligence - NUST (2019â€“2023)\",\n",
    "            \"Intermediate - Punjab College (2017â€“2019)\"\n",
    "        ],\n",
    "        \"work_experience\": [\n",
    "            \"Machine Learning Intern at VisionX (2022)\",\n",
    "            \"Data Analyst at Upwork (2021â€“Present)\"\n",
    "        ],\n",
    "        \"projects\": [\n",
    "            \"Skin Cancer Classifier using CNN\",\n",
    "            \"Resume Parser with SpaCy and Streamlit\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ali Raza\",\n",
    "        \"skills\": [\"Java\", \"Spring Boot\", \"MySQL\"],\n",
    "        \"education\": [],\n",
    "        \"work_experience\": [],\n",
    "        \"projects\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Hira Khalid\",\n",
    "        \"skills\": [\"C++\", \"React\", \"Firebase\", \"Node.js\"],\n",
    "        \"education\": [\"BSCS - FAST NUCES\", \"O & A Levels - Roots International\"],\n",
    "        \"work_experience\": [\"Frontend Developer Intern at Arbisoft\"],\n",
    "        \"projects\": [\"BookMyHall (React + Firebase)\", \"Portfolio website\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Muhammad Azeem\",\n",
    "        \"skills\": [\"Python\", \"Pandas\", \"Streamlit\", \"Vector Databases\", \"Qdrant\", \"Coqui TTS\"],\n",
    "        \"education\": [\"BSCS - FAST (2022â€“2026)\"],\n",
    "        \"work_experience\": [\"AI Intern at Atomcamp\", \"RAG System Developer at Vectorshift\"],\n",
    "        \"projects\": [\n",
    "            \"Roman Urdu to Urdu TTS System using Coqui + ESPnet\",\n",
    "            \"Resume Filter using Pydantic + Qdrant\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "for i, candidate in enumerate(candidates):\n",
    "    insert_candidate(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d7982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate ID: 218321759453493964\n",
      "Name: Sara Qureshi\n",
      "Vectors:\n",
      " - education (384 dims)\n",
      "   [-0.05388639, -0.018306209, 0.0031778235, 0.01587062, 0.019572804, -0.008160581, -0.07396886, -0.03875141, -0.08189774, 0.033437066]...\n",
      " - work_experience (384 dims)\n",
      "   [-0.08474719, -0.037158173, 0.08516825, -0.010177444, -0.0019727254, -0.0562636, 0.004107879, -0.04346316, -0.12105826, -0.031767443]...\n",
      " - skills (384 dims)\n",
      "   [0.011941659, -0.09691213, -0.050752, 0.015720889, 0.015734889, -0.1109149, 0.031121796, -0.046576813, -0.09108185, 0.017807573]...\n",
      " - projects (384 dims)\n",
      "   [-0.040890027, -0.017174944, 0.030739445, 0.013700359, 0.0492771, -0.010928533, 0.060590174, -0.044393994, -0.101692274, -0.09218805]...\n",
      "\n",
      "Candidate ID: 239531732132939857\n",
      "Name: Ali Raza\n",
      "Vectors:\n",
      " - projects (384 dims)\n",
      "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...\n",
      " - work_experience (384 dims)\n",
      "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...\n",
      " - education (384 dims)\n",
      "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...\n",
      " - skills (384 dims)\n",
      "   [-7.410267e-05, -0.024835495, -0.049983755, -0.032076694, -0.060943503, 0.031059349, 0.012389515, 0.079714365, -0.07185782, -0.007908622]...\n",
      "\n",
      "Candidate ID: 5836255493398790999\n",
      "Name: Muhammad Azeem\n",
      "Vectors:\n",
      " - education (384 dims)\n",
      "   [-0.09093871, -0.02192563, -0.004464605, 0.024848463, -0.029250018, 0.031961158, -0.07627908, -0.021618612, -0.060213335, -0.022445114]...\n",
      " - skills (384 dims)\n",
      "   [0.004794068, -0.057768866, -0.05734855, -0.057480924, -0.016929792, -0.015602607, -0.0019984953, -0.016170446, -0.03372266, 0.0065562883]...\n",
      " - work_experience (384 dims)\n",
      "   [-0.055005908, -0.030876553, 0.06224003, -0.01308273, -0.02130248, -0.022667406, 0.005139956, 0.010218721, -0.054303195, 0.002754621]...\n",
      " - projects (384 dims)\n",
      "   [-0.045619916, 0.07196601, -0.047467463, -0.11925875, -0.04277837, 0.047642633, 0.006208699, -0.029422728, -0.028719569, -0.018740118]...\n",
      "\n",
      "Candidate ID: 7922146019806581154\n",
      "Name: Hira Khalid\n",
      "Vectors:\n",
      " - projects (384 dims)\n",
      "   [-0.03680902, -0.02777391, -0.082797706, 0.030692834, 0.016616868, 0.07557018, -0.09727596, 0.009503512, -0.013366829, 0.03769696]...\n",
      " - work_experience (384 dims)\n",
      "   [-0.06242489, 0.011716758, -0.0084307175, -0.02866144, -0.020176178, -0.07439057, 0.012030135, -0.011975046, -0.08594577, -0.0012545682]...\n",
      " - skills (384 dims)\n",
      "   [-0.02639898, 0.03955051, 0.009001173, 0.0325615, 0.020056855, 0.0775524, -0.08418172, 0.108846255, 0.0028708726, -0.011469533]...\n",
      " - education (384 dims)\n",
      "   [-0.03585493, -0.06422848, -0.029692046, 0.04318838, -0.023257239, -0.043540273, -0.07164047, 0.029579544, -0.037384417, -0.003773344]...\n"
     ]
    }
   ],
   "source": [
    "scroll_result = client.scroll(\n",
    "    collection_name=\"cv_data\",\n",
    "    with_payload=True,\n",
    "    with_vectors=True,\n",
    "    limit=100\n",
    ")\n",
    "\n",
    "for point in scroll_result[0]:\n",
    "    print(f\"\\nCandidate ID: {point.id}\")\n",
    "    print(f\"Name: {point.payload.get('name', 'N/A')}\")\n",
    "    print(\"Vectors:\")\n",
    "    for vector_name, vector_values in point.vector.items():\n",
    "        print(f\" - {vector_name} ({len(vector_values)} dims)\")\n",
    "        print(f\"   {vector_values[:10]}...\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0bcc8",
   "metadata": {},
   "source": [
    "## Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15552db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_user_requirements():\n",
    "    print(\"Please enter your ideal candidate profile requirements.\")\n",
    "    fields = [\"skills\", \"experience\", \"education\", \"projects\"]\n",
    "\n",
    "    query_texts = {}\n",
    "    weights = {}\n",
    "\n",
    "    for field in fields:\n",
    "        value = input(f\"\\nðŸ”¹ Enter desired {field.replace('_', ' ')} (comma-separated or free text):\\n> \")\n",
    "        query_texts[field] = value.strip()\n",
    "\n",
    "    print(\"\\nNow assign a weight to each field (between 0.0 and 1.0). Total doesn't need to be 1.\")\n",
    "    for field in fields:\n",
    "        while True:\n",
    "            try:\n",
    "                w = float(input(f\"Weight for {field}: \"))\n",
    "                if 0 <= w <= 1:\n",
    "                    weights[field] = w\n",
    "                    break\n",
    "                else:\n",
    "                    print(\" Must be between 0 and 1.\")\n",
    "            except ValueError:\n",
    "                print(\" Invalid number, try again.\")\n",
    "\n",
    "    return query_texts, weights\n",
    "\n",
    "# Get dynamic user input\n",
    "query_texts, weights = get_user_requirements()\n",
    "\n",
    "print(\"\\nâœ… Final Input Summary:\")\n",
    "print(\"User Prompt:\", query_texts)\n",
    "print(\"Weights:\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f112c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
