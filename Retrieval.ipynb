{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Azeem\\Documents\\CARE\\Intelligent-Resume-Filtering\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "import fitz \n",
    "from pydantic import BaseModel\n",
    "import os \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time \n",
    "from openai import OpenAI\n",
    "import json \n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, Distance, VectorParams\n",
    "import numpy as np \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c05b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "def pdf_to_text(pdf_path: str) -> str:\n",
    "    elements = partition_pdf(pdf_path, strategy=\"fast\")\n",
    "    return \"\\n\".join([el.text.strip() for el in elements if el.text.strip()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308a8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining schema for input \n",
    "\n",
    "class ResumeInfo(BaseModel):\n",
    "    name: str\n",
    "    skills: list = []\n",
    "    education: list = []\n",
    "    work_experience: list = []\n",
    "    projects: list = []\n",
    "    filepath : str \n",
    "\n",
    "\n",
    "json_schema = ResumeInfo.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62de426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7df14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e17b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_call(prompt):\n",
    "    client = OpenAI(\n",
    "    base_url=\"http://172.16.2.214:8000/v1\", \n",
    "    api_key=\"-\" \n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-32B-Instruct-AWQ\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "   \n",
    "   extra_body={\"guided_json\": json_schema}\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d24c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the prompt as an input to the LLM \n",
    "def parsing_helper(markdown_text,filepath):\n",
    "  prompt = f\"\"\"\n",
    "  You are a precise and strict **Information Extraction Assistant**.\n",
    "\n",
    "  Your task is to extract structured data from **unstructured CV text**, strictly following the provided JSON schema.\n",
    "  add this filepath as well {filepath}\n",
    "\n",
    "  json schema as follow : \n",
    "        name: str\n",
    "        skills: list = []\n",
    "        education: list = []\n",
    "        work_experience: list = []\n",
    "        projects: list = []\n",
    "        filepath : str \n",
    "    \n",
    "\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Rules:\n",
    "  - Only extract information that is **explicitly stated** in the CV text.\n",
    "  - If a field is **missing**, use:'\n",
    "    - `null` for missing strings\n",
    "    - `[]` for missing lists\n",
    "  - Do **not** hallucinate, infer, summarize, or rewrite content.\n",
    "  - Preserve original text exactly as it appears.\n",
    "  - Return a **valid JSON object only** — no markdown, no extra explanation.\n",
    "  ### CV Text: \n",
    "\n",
    "  {markdown_text}\n",
    "\n",
    "  ### Output(matches the schema):\n",
    "\"\"\"\n",
    "  \n",
    "  return LLM_call(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e06d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parser_pipeline(path):\n",
    "    candidates = []\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"{path} is not a valid directory!\")\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        ##Calling pdf_to_text and converting each into text and passing it to the llm \n",
    "\n",
    "        print(\"Converting CV to text\")\n",
    "\n",
    "        text =  pdf_to_text(file_path)\n",
    "        \n",
    "        ## passing it to the LLM \n",
    "        structured_output = parsing_helper(text,file_path)\n",
    "\n",
    "        candidates.append(structured_output)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235ff422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CV to text\n",
      "{\n",
      "  \"name\": \"AHMAD RASHAD MOJEEB\",\n",
      "  \"skills\": [\n",
      "    \"Project Management: Hands-on experience with Jira for tracking tasks and managing sprints\",\n",
      "    \"Frameworks & Tools: Spring Boot, .NET, React, Git, MySQLL\",\n",
      "    \"Development Areas: Full-Stack Development, Game Development, and Operating Systems Simulation\",\n",
      "    \"Deployment: Docker (Containerisation), Website Deployment\",\n",
      "    \"Programming Languages: Java, Python, C#, SQL, Assembly, C++, C\"\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Computer Science\",\n",
      "      \"institution\": \"FAST | nuces\",\n",
      "      \"years\": \"2022-2026\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Alevels\",\n",
      "      \"institution\": \"Supernova school\",\n",
      "      \"years\": \"2020-2022\",\n",
      "      \"details\": \"1Astar 2As\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Olevels\",\n",
      "      \"institution\": \"Supernova school\",\n",
      "      \"years\": \"2018-2020\",\n",
      "      \"details\": \"6Astar 2As\"\n",
      "    }\n",
      "  ],\n",
      "  \"work_experience\": [],\n",
      "  \"projects\": [\n",
      "    \"SportSync – Full-Stack Sports Event Management System (Spring Boot + React + api integration - worked as scrum master)\",\n",
      "    \"BookYourHall – Full-Stack Web Application (Spring Boot + React + mySQL)\",\n",
      "    \"ShopVerse – Online Marketplace Database System (C# .net + SQL)\",\n",
      "    \"TORCS Car Racing Simulation – Implemented using AI (Python, mlp-regressor)\",\n",
      "    \"Multi-Robot Path Planning in Dynamic Partially Observable Environments (Pyhton)\",\n",
      "    \"Road Junction – Traffic Light Simulation (C++, implemented POSIX threads, thread synchronization and thread communication)\",\n",
      "    \"Pac-Man – Classic Arcade Game (Assembly Language)\",\n",
      "    \"Enchanted Labyrinth Explorer – Maze Navigation Game (C++, utilized AVL trees and path finding algorithms(dijkstra) for maze navigation)\",\n",
      "    \"Dodge Em – Object-Oriented Game (C++, Focus on OOP principles eg encapsulation, abstraction, inheritance and polymorphism)\",\n",
      "    \"Chess Game (C++)\",\n",
      "    \"Tetris (C++)\"\n",
      "  ],\n",
      "  \"filepath\": \"Resumes\\\\Ahmad Rashad (7).pdf\"\n",
      "}\n",
      "Converting CV to text\n",
      "{\n",
      "  \"name\": \"Muhammad Azeem Chaudhry\",\n",
      "  \"skills\": [\n",
      "    \"Python: LLMs (Hugging Face Transformers, SpeechT5, RoBERTa), PyTorch, NLTK, Flask, Streamlit, gRPC, Pandas, NumPy, Matplotlib, OpenCV, Scikit-Learn, Jupyter, Librosa, PyAudio, SentencePiece, Torchaudio\",\n",
      "    \"Machine Learning: Logistic Regression, Decision Trees, Random Forest, Gradient Descent, Support Vector Machines (SVM), Artificial Neural Networks (ANN), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Batch Normalization, Dropout, K-Means Clustering, K-Nearest Neighbors (KNN), PCA, Activation Functions, Backpropagation\",\n",
      "    \"NLP: Tokenisation, Text Preprocessing, Sentiment Analysis, Transformer Architectures, Attention Mechanisms, Sequence-to-Sequence Models, SpeechT5, RoBERTa, Cross-Task Attention, Word Embeddings (Word2Vec), Intent & Slot Modeling\",\n",
      "    \"Deployment and Tools: Docker, gRPC, Postman, Streamlit, Git, Linux CLI, SPARQL, Jupyter, Colab, Kaggle\",\n",
      "    \"Database Management: SQL, JSON, REST APIs\",\n",
      "    \"C/C++: Object-Oriented Programming, Data Structures, File I/O, STL, Multithreading\",\n",
      "    \"Java Script (Basic)\",\n",
      "    \"Soft Skills: Problem Solving and Analytical Thinking, Communication and Collaboration, Time Management and Multitasking, Adaptability in Fast-Paced Environments, Initiative and Self-Learning, Technical Documentation and Reporting\"\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Bachelor's\",\n",
      "      \"institution\": \"FAST, BS Artificial Intelligence\",\n",
      "      \"years\": \"2022 – 2026\",\n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"main_courses\": [\n",
      "        \"Artificial Neural Networks\",\n",
      "        \"Database Systems\",\n",
      "        \"Parallel and Distributed Computing\",\n",
      "        \"Natural Language Processing\",\n",
      "        \"Digital Image Processing\",\n",
      "        \"Artificial Intelligence\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"position\": \"AI/ML Developer Intern\",\n",
      "      \"company\": \"Atom Camp\",\n",
      "      \"dates\": \"08/2024 – 01/2025\",\n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"description\": \"Contributed to the design and deployment of AI solutions, including LLM-based chatbots and learning management tools. Focused on enhancing user interactions, improving model responses, and supporting system scalability through Python, Transformers, and RESTful APIs.\"\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"AI intern\",\n",
      "      \"company\": \"Atom Camp\",\n",
      "      \"dates\": \"07/2024 – 08/2024\",\n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"description\": \"Collaborated with a team to develop a chatbot for Atomcamp's website using Google API and open-source LLMs, enhancing user interaction and support. Contributed to the development of an automated attendance system, streamlining daily attendance data into a consolidated record.\"\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Software Developer Intern\",\n",
      "      \"company\": \"E-strats\",\n",
      "      \"dates\": \"06/2021 – 07/2021\",\n",
      "      \"location\": \"Islamabad, Pakistan\",\n",
      "      \"description\": \"Developed and maintained web applications using .NET and C#. Worked on user interfaces with HTML and CSS. Participated in code reviews to ensure code quality and adherence to standards.\"\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Text2Story\",\n",
      "      \"description\": \"Developed an AI-driven audio storytelling system that converts written narratives into expressive audio using SpeechT5 with contextual prosody, leveraging Librosa, Torchaudio, and Parler TTS for tone modulation and voice synthesis. Integrated data preprocessing and model orchestration with PyTorch and Transformers.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Traffic Sign Classification\",\n",
      "      \"description\": \"Designed a rule-based image classifier using NumPy and traditional computer vision techniques to detect traffic signs based on color, shape, and geometric features, emphasizing computational efficiency over deep learning approaches.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"CTRA-N Based NLP Enhancements\",\n",
      "      \"description\": \"Reproduced and enhanced the CTRAN model by replacing BERT with RoBERTa and integrating cross-task attention mechanisms, resulting in improved performance on standard NLU benchmarks for intent classification and slot filling.\"\n",
      "    }\n",
      "  ],\n",
      "  \"filepath\": \"Resumes\\\\Muhammad Azeem Chaudhry's Resume.pdf\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "candidates = cv_parser_pipeline(\"Resumes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a342d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azeem\\AppData\\Local\\Temp\\ipykernel_23440\\3333303549.py:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  \n",
    "client.recreate_collection(\n",
    "collection_name=\"cv_data\",\n",
    "vectors_config={\n",
    "    \"skills\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"education\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"work_experience\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"projects\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38a0844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_fields = [\"skills\", \"education\", \"work_experience\", \"projects\"]\n",
    "\n",
    "###-------------------------------------------------------------------------\n",
    "def zero_vector(dim=384):\n",
    "    return [0.0] * dim\n",
    "###-------------------------------------------------------------------------\n",
    "def join_and_embed(field_list,embedding_model):\n",
    "    if not field_list:\n",
    "        return zero_vector()  \n",
    "    pieces = []\n",
    "    for item in field_list:\n",
    "        if isinstance(item, dict):\n",
    "         \n",
    "            pieces.append(\", \".join(f\"{k}: {v}\" for k, v in item.items()))\n",
    "        elif isinstance(item, str):\n",
    "            pieces.append(item)\n",
    "        else:\n",
    "       \n",
    "            pieces.append(str(item))\n",
    "    text = \" \".join(pieces)\n",
    "    return embedding_model.encode([text])[0].tolist()\n",
    "\n",
    "###-----------------------------------------------------------------------\n",
    "def insert_candidate(candidate, collection_name=\"cv_data\"):\n",
    "    vector_data = {\n",
    "        field: join_and_embed(candidate.get(field, []),embedding_model)\n",
    "        for field in required_fields\n",
    "    }\n",
    "    \n",
    "    payload = {}\n",
    "    if \"name\" in candidate:\n",
    "        payload[\"name\"] = candidate[\"name\"]\n",
    "    if \"filepath\" in candidate: \n",
    "        payload[\"filepath\"] = candidate[\"filepath\"]\n",
    "\n",
    "    # Point ID\n",
    "    point_id = candidate.get(\"id\", hash(candidate.get(\"name\", \"unknown\")) & 0xFFFFFFFFFFFFFFFF)\n",
    "\n",
    "    point = PointStruct(\n",
    "        id=point_id,\n",
    "        vector=vector_data,\n",
    "        payload=payload\n",
    "    )\n",
    "    \n",
    "    client.upsert(collection_name=collection_name, points=[point])\n",
    "    print(f\"Inserted: {payload.get('name', 'Unnamed')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a63b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating VEC DB \n",
    "def create_vec_db(candidates):\n",
    "    for i, candidate in enumerate(candidates): \n",
    "        print(\"Inserting candidate\")\n",
    "        insert_candidate(candidate)\n",
    "    scroll_result = client.scroll(\n",
    "    collection_name=\"cv_data\",\n",
    "    with_payload=True,\n",
    "    with_vectors=True,\n",
    "    limit=100\n",
    ")\n",
    "\n",
    "    for point in scroll_result[0]:\n",
    "        print(f\"\\nCandidate ID: {point.id}\")\n",
    "        print(f\"Name: {point.payload.get('name', 'N/A')}\")\n",
    "        print(f\"Filepath: {point.payload.get('filepath', 'N/A')}\")  # ✅ This line shows the path\n",
    "        print(\"Vectors:\")\n",
    "        for vector_name, vector_values in point.vector.items():\n",
    "            print(f\" - {vector_name} ({len(vector_values)} dims)\")\n",
    "            print(f\"   {vector_values[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f96d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting candidate\n",
      "Inserted: AHMAD RASHAD MOJEEB\n",
      "Inserting candidate\n",
      "Inserted: Muhammad Azeem Chaudhry\n",
      "\n",
      "Candidate ID: 15029620614353576281\n",
      "Name: Muhammad Azeem Chaudhry\n",
      "Filepath: Resumes\\Muhammad Azeem Chaudhry's Resume.pdf\n",
      "Vectors:\n",
      " - education (384 dims)\n",
      "   [-0.021256179, -0.085238256, 0.02810062, 0.023358196, -0.05861551, -0.058037534, -0.08238744, -0.017035617, -0.083069034, 0.00675746]...\n",
      " - skills (384 dims)\n",
      "   [-0.08107303, -0.18257825, -0.008319617, -0.0040023117, 0.06360502, -0.0043624775, -0.048732035, 0.030923348, -0.017590592, -0.009718532]...\n",
      " - projects (384 dims)\n",
      "   [-0.03959531, -0.09473572, 0.025652448, -0.054258443, 0.0010956578, 0.029833755, -0.0011511324, -0.051974535, -0.0009792366, -0.08130918]...\n",
      " - work_experience (384 dims)\n",
      "   [-0.05999295, -0.026150364, 0.014208963, 0.021188542, 0.024000205, -0.04163701, 0.0057619046, -0.0010891248, -0.035834394, -0.028546486]...\n",
      "\n",
      "Candidate ID: 15308989954804716007\n",
      "Name: AHMAD RASHAD MOJEEB\n",
      "Filepath: Resumes\\Ahmad Rashad (7).pdf\n",
      "Vectors:\n",
      " - work_experience (384 dims)\n",
      "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...\n",
      " - education (384 dims)\n",
      "   [-0.053980503, -0.019842958, -0.009073828, -0.0061391923, -0.049654197, -0.08667646, -0.12778819, -0.018757055, -0.05415736, -0.02093313]...\n",
      " - projects (384 dims)\n",
      "   [-0.006470157, -0.02375167, -0.035813525, -0.060372084, -0.03393049, -0.012579661, -0.064161524, 0.03796895, -0.08588304, 0.06814528]...\n",
      " - skills (384 dims)\n",
      "   [-0.05399983, -0.024360845, -0.009617732, 0.009675335, 0.0064823, -0.068843395, 0.028106099, -0.0030010412, -0.06823482, 0.069343664]...\n"
     ]
    }
   ],
   "source": [
    "create_vec_db(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f15552db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_description_parser(job_description) : \n",
    "    \n",
    "    job_prompt = f\"\"\"\n",
    "    You are an **Information Extraction Assistant**.\n",
    "\n",
    "    Your task:\n",
    "    - Parse the provided **job description**.\n",
    "    - Extract **explicit information only** — ***do not infer, invent, or assume***.\n",
    "    - Output a **valid JSON object** that matches the schema shown below.\n",
    "\n",
    "    ### JSON schema:\n",
    "    {{\n",
    "    \"skills\": [ \"list of required skills as short strings\" ],\n",
    "    \"work_experience\": \"explicit description of required work experience, as a string\",\n",
    "    \"education\": \"explicit education or qualification requirements, as a string\",\n",
    "    \"projects\": [ \"list of explicitly mentioned types of projects or domains\" ]\n",
    "    }}\n",
    "\n",
    "    ### Rules:\n",
    "    - If a field is not present in the job description, use:\n",
    "    - an empty list `[]` for list fields,\n",
    "    - or `null` for string fields.\n",
    "    - Do **not** add any extra text outside the JSON.\n",
    "    - Do **not** add markdown or explanations.\n",
    "    - Preserve the original wording of the job description when filling fields.\n",
    "\n",
    "    ### Job Description:\n",
    "    {job_description}\n",
    "    ### Output(matches the schema):\n",
    " \"\"\"\n",
    "\n",
    "    return LLM_call(job_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041884e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a96be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Junior AI Engineer\",\n",
      "    \"skills\": [\"Python\", \"NumPy\", \"Pandas\", \"TensorFlow\", \"PyTorch\", \"data structures\", \"algorithms\", \"Git\", \"version control\", \"communication\", \"teamwork\"],\n",
      "    \"work_experience\": [\"Prior experience with Git and version control.\", \"Strong communication and teamwork skills.\"],\n",
      "    \"projects\": [\"GitHub\", \"Kaggle\", \"any relevant work that showcases your ML projects\"]\n",
      "  ,\n",
      "    \"filepath\": \"json_output/job_description_junior_ai_engineer.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_description = input(\"***Please Enter the Job Description***\")\n",
    "parsed__job_description = job_description_parser(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f112c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter weight for each field. Total should sum to 1 (e.g. 0.4, 0.2, etc.)\n",
      "\n",
      " Total weight entered is 1.300, normalizing to 1.\n",
      "\n",
      " Normalized Weights:\n",
      "  skills: 0.154\n",
      "  education: 0.077\n",
      "  work_experience: 0.308\n",
      "  projects: 0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azeem\\AppData\\Local\\Temp\\ipykernel_23440\\3425504140.py:39: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  hits = client.search(\n"
     ]
    }
   ],
   "source": [
    "job_vectors = {\n",
    "    field: join_and_embed(parsed__job_description.get(field, []), embedding_model)\n",
    "    for field in required_fields\n",
    "}\n",
    "\n",
    "fields = [\"skills\", \"education\", \"work_experience\", \"projects\"]\n",
    "user_weights_raw = {}\n",
    "\n",
    "print(\"Please enter weight for each field. Total should sum to 1 (e.g. 0.4, 0.2, etc.)\")\n",
    "\n",
    "# Step 1: Get input for each field\n",
    "for field in fields:\n",
    "    while True:\n",
    "        try:\n",
    "            weight = float(input(f\"Enter weight for '{field}': \"))\n",
    "            if weight < 0:\n",
    "                raise ValueError\n",
    "            user_weights_raw[field] = weight\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a non-negative number.\")\n",
    "\n",
    "total_weight = sum(user_weights_raw.values())\n",
    "\n",
    "if abs(total_weight - 1.0) > 1e-6:\n",
    "    print(f\"\\n Total weight entered is {total_weight:.3f}, normalizing to 1.\")\n",
    "    user_weights = {k: v / total_weight for k, v in user_weights_raw.items()}\n",
    "else:\n",
    "    user_weights = user_weights_raw\n",
    "\n",
    "print(\"\\n Normalized Weights:\")\n",
    "for field, weight in user_weights.items():\n",
    "    print(f\"  {field}: {weight:.3f}\")\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for field in required_fields:\n",
    "    hits = client.search(\n",
    "        collection_name=\"cv_data\",\n",
    "        query_vector=(field, job_vectors[field]),  # Named vector search\n",
    "        limit=5,  # Top 5 candidates\n",
    "        with_payload=True,\n",
    "        with_vectors=False  # No need to return full vectors now\n",
    "    )\n",
    "    results[field] = hits\n",
    "\n",
    "\n",
    "score_board = defaultdict(float)\n",
    "\n",
    "for field in results:\n",
    "    weight = user_weights.get(field, 0)\n",
    "    for hit in results[field]:\n",
    "        score_board[hit.id] += hit.score * weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f540344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Top 10 matching candidates:\n",
      "\n",
      "Name: Muhammad Azeem Chaudhry\n",
      "Filepath: Resumes\\Muhammad Azeem Chaudhry's Resume.pdf\n",
      "Score: 0.1723\n",
      "\n",
      "Name: AHMAD RASHAD MOJEEB\n",
      "Filepath: Resumes\\Ahmad Rashad (7).pdf\n",
      "Score: 0.1467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_k = int(input(\"Enter number of top candidates to display: \"))\n",
    "\n",
    "ranked = sorted(score_board.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_candidates = []  \n",
    "\n",
    "print(f\"\\n🔍 Top {top_k} matching candidates:\\n\")\n",
    "shown = 0\n",
    "\n",
    "for candidate_id, total_score in ranked:\n",
    "    point = next(\n",
    "        (pt for pt in client.scroll(\n",
    "            collection_name=\"cv_data\",\n",
    "            with_payload=True,\n",
    "            with_vectors=False,\n",
    "            limit=100\n",
    "        )[0] if pt.id == candidate_id),\n",
    "        None\n",
    "    )\n",
    "    if point:\n",
    "        candidate_info = {\n",
    "            \"name\": point.payload.get(\"name\"),\n",
    "            \"filepath\": point.payload.get(\"filepath\"),\n",
    "            \"score\": round(total_score, 4),\n",
    "            \"id\": candidate_id\n",
    "        }\n",
    "        top_candidates.append(candidate_info)\n",
    "\n",
    "        # Display\n",
    "        print(f\"Name: {candidate_info['name']}\")\n",
    "        print(f\"Filepath: {candidate_info['filepath']}\")\n",
    "        print(f\"Score: {candidate_info['score']}\\n\")\n",
    "\n",
    "        shown += 1\n",
    "    if shown >= top_k:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60167294",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = f\"\"\" You are an expert technical recruiter and AI career advisor. Use the information provided below to perform an in-depth candidate evaluation using semantic embeddings retrieved from a vector database (Qdrant).\n",
    "\n",
    "---\n",
    "\n",
    "### 🧾 Job Description\n",
    "\n",
    "{job_description}\n",
    "---\n",
    "\n",
    "### 📌 Top {top_k} Candidates from Vector Similarity Search : {top_candidates}\n",
    "\n",
    "These candidates were retrieved from the Qdrant vector database based on semantic similarity to the job description. Each candidate includes their resume filepath,a vector similarity score and id.\n",
    "---\n",
    "\n",
    "Here is all the candidates \n",
    "{candidates}\n",
    "\n",
    "### 🎯 Task\n",
    "\n",
    "Analyze the candidates above with respect to the job description and perform the following:\n",
    "\n",
    "1. **Compare** each candidate's qualifications with the job description in terms of:\n",
    "   - Skills\n",
    "   - Work experience\n",
    "   - Relevant projects\n",
    "   - Educational background\n",
    "\n",
    "2. **Rank** the candidates from most to least suitable based on the job description and vector match scores.\n",
    "\n",
    "3. **Justify** your top 1–2 recommendations with detailed reasoning, focusing on fit for the role. Also the decision should not be eccentric to the match scores\n",
    "\n",
    "4. **Highlight Gaps**:\n",
    "   - Are there any key missing skills or misalignments?\n",
    "   - Are there strengths that go beyond the role?\n",
    "\n",
    "5. **Provide Insights**:\n",
    "   - Strengths and weaknesses of each candidate\n",
    "   - A comparison table showing each candidate's match to the job requirements\n",
    "   - Visual ideas: skill coverage bar chart or score comparison chart\n",
    "   - Suggest which candidate fits which kind of sub-role (e.g., research-focused, full-stack AI, deployment)\n",
    "\n",
    "6. Write in a **professional tone** suitable for HR and technical hiring managers.\n",
    "\n",
    "---\n",
    "\n",
    "Your goal is to aid the hiring manager in making a well-informed and confident decision based on both semantic similarity and practical job fit. Dont disclose any scores to the user in the output \n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb864ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Candidate Evaluation Report\n",
      "\n",
      "#### Overview\n",
      "\n",
      "This report evaluates two top candidates for the Junior AI Engineer position at TechVision based on their resumes and vector similarity scores. The analysis covers skills, work experience, relevant projects, educational background, and alignment with the job description.\n",
      "\n",
      "#### Candidate Comparison\n",
      "\n",
      "| Criteria           | Muhammad Azeem Chaudhry                          | AHMAD RASHAD MOJEEB                             |\n",
      "|--------------------|--------------------------------------------------|--------------------------------------------------|\n",
      "| **Skills**         | Strong in Python, Machine Learning, NLP, Docker  | Broad range in Full-Stack Development, Game Dev  |\n",
      "| **Work Experience**| Multiple internships in AI/ML                     | None                                             |\n",
      "| **Projects**       | AI-driven audio systems, Traffic Sign Classifier  | Full-Stack sports event management               |\n",
      "| **Education**      | FAST, BS Artificial Intelligence                  | FAST, Bachelor of Computer Science               |\n",
      "\n",
      "### Detailed Analysis\n",
      "\n",
      "#### Muhammad Azeem Chaudhry\n",
      "\n",
      "- **Skills**: Extensive experience with Python, PyTorch, TensorFlow, NLP frameworks (Hugging Face Transformers, RoBERTa), and deployment tools (Docker, gRPC). Matches the required Python, NumPy, Pandas, TensorFlow/PyTorch, and preferred Docker, MLOps, and cloud platforms.\n",
      "  \n",
      "- **Work Experience**: Multiple internships at Atom Camp and E-strats, focusing on AI/ML solutions, chatbots, and web application development. This aligns well with the requirement for prior experience and familiarity with Git and version control.\n",
      "  \n",
      "- **Projects**: Developed AI-driven audio storytelling systems and traffic sign classifiers, showcasing strong skills in NLP and machine learning. This aligns with the responsibilities of developing and optimizing machine learning models for NLP tasks and integrating them into production-ready APIs.\n",
      "  \n",
      "- **Education**: Currently pursuing a Bachelor's degree in Artificial Intelligence from FAST, with relevant courses in AI, NLP, and machine learning. Matches the requirement for a Bachelor’s degree in Computer Science, AI, Data Science, or a related field.\n",
      "  \n",
      "- **Gaps**: No specific mention of cloud platforms like AWS/GCP, but strong foundational skills can be built upon.\n",
      "\n",
      "#### AHMAD RASHAD MOJEEB\n",
      "\n",
      "- **Skills**: Broad range in full-stack development, game development, and operating systems simulation. Familiarity with Java, Python, C#, SQL, and Assembly. Matches the required Python and preferred knowledge of frameworks like HuggingFace Transformers and scikit-learn.\n",
      "  \n",
      "- **Work Experience**: No professional work experience listed. This could be a gap compared to the requirement for prior experience, especially in machine learning.\n",
      "  \n",
      "- **Projects**: Developed full-stack sports event management systems and game simulations. Demonstrates strong problem-solving skills and proficiency in multiple programming languages. However, the projects do not directly align with machine learning and NLP tasks.\n",
      "  \n",
      "- **Education**: Pursuing a Bachelor’s degree in Computer Science from FAST, with strong academic achievements. Matches the requirement for a Bachelor’s degree in Computer Science, AI, Data Science, or a related field.\n",
      "  \n",
      "- **Gaps**: Lack of direct machine learning and NLP experience. Projects focus more on full-stack development rather than machine learning.\n",
      "\n",
      "### Ranking\n",
      "\n",
      "1. **Muhammad Azeem Chaudhry**\n",
      "   - **Vector Match Score**: 0.1723\n",
      "   - **Reasoning**: Strong alignment with the required skills, relevant work experience, and projects directly related to the job responsibilities.\n",
      "   \n",
      "2. **AHMAD RASHAD MOJEEB**\n",
      "   - **Vector Match Score**: 0.1467\n",
      "   - **Reasoning**: Broad skill set and strong academic background, but lacks direct machine learning experience and relevant projects.\n",
      "\n",
      "### Top Recommendations\n",
      "\n",
      "#### Top 1: Muhammad Azeem Chaudhry\n",
      "\n",
      "- **Strengths**: Strong foundation in Python, machine learning, and NLP. Relevant internships and projects that align closely with the job responsibilities.\n",
      "- **Weaknesses**: No specific mention of cloud platforms like AWS/GCP, though this can be addressed through training.\n",
      "\n",
      "#### Top 2: AHMAD RASHAD MOJEEB\n",
      "\n",
      "- **Strengths**: Broad skill set in full-stack development and game development. Strong academic background.\n",
      "- **Weaknesses**: Lack of direct machine learning experience and relevant projects. Might require additional training in machine learning and NLP.\n",
      "\n",
      "### Insights\n",
      "\n",
      "- **Skill Coverage Bar Chart**: A visual representation of how each candidate's skills map to the job requirements would highlight the strengths and gaps clearly.\n",
      "- **Comparison Table**: The table above provides a quick reference for comparing each candidate's fit to the job requirements.\n",
      "- **Sub-Role Fit**: \n",
      "  - **Research-Focused**: Muhammad Azeem Chaudhry, given his extensive experience in machine learning and NLP.\n",
      "  - **Full-Stack AI**: AHMAD RASHAD MOJEEB, due to his broad skill set in full-stack development and game development.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Based on the detailed analysis, Muhammad Azeem Chaudhry is the most suitable candidate for the Junior AI Engineer position at TechVision, closely followed by AHMAD RASHAD MOJEEB. Both candidates have strong potential, but Muhammad Azeem Chaudhry has a better alignment with the job requirements and vector match scores.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "base_url=\"http://172.16.2.214:8000/v1\", \n",
    "api_key=\"-\" \n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "model=\"Qwen/Qwen2.5-32B-Instruct-AWQ\",\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": prompt_3}\n",
    "    ],\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f0aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
